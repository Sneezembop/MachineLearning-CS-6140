{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4 - Miles Benjamin - CS 6140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as scio\n",
    "import pprint as pp\n",
    "import skimage as ski\n",
    "import skimage.transform as skit\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Feed Forward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the data is [10]\n",
      "shape of the data is [192, 168, 50]\n",
      "shape of the data is [10, 1]\n"
     ]
    }
   ],
   "source": [
    "mat = scio.loadmat('./ExtYaleB10.mat')\n",
    "#pp.pprint(mat)\n",
    "Y_test = mat['test']\n",
    "Y_train = mat['train']\n",
    "#print(Y_train[0])\n",
    "print('shape of the data is [%d]' % Y_train[0].shape)\n",
    "print('shape of the data is [%d, %d, %d]' % Y_train[0][0].shape)\n",
    "Y = np.mat(Y_train).T\n",
    "print('shape of the data is [%d, %d]' % Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input the array of 50 images\n",
    "def downsampleImage(imgs):\n",
    "    img = []\n",
    "    temp = []\n",
    "    for i in range(len(imgs[0][0])):\n",
    "            img = imgs[:][:][i]\n",
    "            img = skit.resize(img,[20,17],mode='constant').flatten()\n",
    "            temp.append(img)\n",
    "            \n",
    "    #print(np.array(temp).shape)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = downsampleImage(Y_train[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rec(x):\n",
    "    if (x < 0):\n",
    "        x = 0\n",
    "    return x    \n",
    "def sig(x):\n",
    "    x = np.exp(x)\n",
    "    x += 1\n",
    "    x = 1/x\n",
    "    return x\n",
    "    \n",
    "def ht(x):\n",
    "    temp = np.exp(x) - np.exp(-x)\n",
    "    temp = temp /(np.exp(x) + np.exp(-x))\n",
    "    return temp\n",
    "\n",
    "def activationFunc(X, activ):\n",
    "    if (activ == 'rec'):\n",
    "        for i in range(len(X)):\n",
    "            X[i] = rec(X[i])\n",
    "            return X\n",
    "    elif (activ == 'sig'):\n",
    "        for i in range(len(X)):\n",
    "            X[i] = sig(X[i])\n",
    "            return X\n",
    "    elif (activ == 'ht'):\n",
    "        for i in range(len(X)):\n",
    "            X[i] = ht(X[i])\n",
    "            return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recD(x):\n",
    "    if (x <= 0):\n",
    "        return 0\n",
    "    return 1\n",
    "def sigD(x):\n",
    "    y = sig(x) * (1- sig(x))\n",
    "    return y\n",
    "    \n",
    "def htD(x):\n",
    "    temp = 1- np.tanh(x)**2\n",
    "    return temp\n",
    "\n",
    "def activationFuncD(X, activ):\n",
    "    if (activ == 'rec'):\n",
    "        for i in range(len(X)):\n",
    "            X[i] = recD(X[i])\n",
    "            return X\n",
    "    elif (activ == 'sig'):\n",
    "        for i in range(len(X)):\n",
    "            X[i] = sigD(X[i])\n",
    "            return X\n",
    "    elif (activ == 'ht'):\n",
    "        for i in range(len(X)):\n",
    "            X[i] = htD(X[i])\n",
    "            return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0066927509923217993], [0.46211715726000979], [0.0066927509923217993], [0.46211715726000979], [0.0066927509923217993], [0.46211715726000979]]\n"
     ]
    }
   ],
   "source": [
    "temp = ['rec', 'sig', 'ht']\n",
    "temp2 = [[5], [-5]]\n",
    "\n",
    "temp3 = []\n",
    "for i in range(len(temp)):\n",
    "    for j in range(len(temp2)):\n",
    "        temp3.append(activationFunc(temp2[j], temp[i]))\n",
    "\n",
    "print(temp3)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# W's shape is as follows: W[l][s(l+1)][s(l)]\n",
    "\n",
    "def FFNN_Initialize(data, s1, s2, s3):\n",
    "    X = [0] * s1\n",
    "    X = np.mat(X)\n",
    "    Y = []\n",
    "    temp = 0\n",
    "    tempx = []\n",
    "    cat = len(data[0])\n",
    "    for i in range(len(data[0])):\n",
    "        tempx = downsampleImage(data[0][i])\n",
    "        tempx = np.mat(tempx)   \n",
    "        X = np.vstack((X,tempx))\n",
    "        temp = [i/cat] * len(tempx)\n",
    "        Y.append(temp)\n",
    "    \n",
    "    X = X[1:][:]\n",
    "    Y = np.array(Y).flatten()\n",
    "    \n",
    "    B = []\n",
    "    S = [s1,s2,s3,1]\n",
    "    W = [0] * 3\n",
    "    for i in range(len(W)):\n",
    "        W[i] = [0] * S[i+1]\n",
    "        for j in range(len(W[i])):\n",
    "            W[i][j] = [np.random.rand() * 0.0001] * S[i]\n",
    "       \n",
    "    for i in range(len(S) -2):\n",
    "        B.append(np.random.rand() * 0.0001)\n",
    "    \n",
    "    return X,Y,W,B,S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FFNN_FeedForward(xi,yi,W,B,S, activ):\n",
    "    L = (len(S) -1)\n",
    "    Z = [0] * L\n",
    "    A = [0] * L\n",
    "    \n",
    "    Z[0] = xi\n",
    "    A[0] = xi\n",
    "    lastA = xi\n",
    "    for i in range(L - 1):\n",
    "        temp = [0]*S[i+1]\n",
    "  \n",
    "        for j in range(S[i+1]):\n",
    "            temp[j] = np.mat(lastA) * np.mat(W[i][j]).T\n",
    "            temp[j] += B[i]\n",
    "            temp[j] = temp[j].A1.tolist()\n",
    "        \n",
    "        temp = np.mat(temp).T.A\n",
    "        \n",
    "        Z[i+1] = temp[0]\n",
    "        A[i+1] = activationFunc(temp[0], activ)\n",
    "       # if (i +1 == 2):\n",
    "           # print(temp, A[i +1], yi)\n",
    "        lastA = A[i+1]\n",
    "    \n",
    "    \n",
    "    return Z,A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FFNN_BackProp(Z,A,yi,W,B,S, activ, ro):\n",
    "    L = len(S) -1\n",
    "    Delta = [0] * L\n",
    "    \n",
    "    Delta[L-1] = np.multiply((A[L-1] - yi),activationFuncD(np.mat(Z[L-1]).T.A, activ))\n",
    "   # print(Delta[L-1])\n",
    "    for i in range(L -2, -1, -1):\n",
    "        # print(np.array(Z[i]).shape)\n",
    "        Delta[i] = np.multiply(np.mat(W[i]).T * np.mat(Delta[i+1]),activationFuncD(np.mat(Z[i]).T.A, activ))\n",
    "    \n",
    "    #print(Delta)\n",
    "    for i in range(L -1):\n",
    "        W[i] = W[i] - ro * (Delta[i+1] * np.mat(A[i]))\n",
    "        B[i] = B[i] - ro * np.sum(Delta[i +1])\n",
    "    \n",
    "    return W,B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activ takes the following values: sig, ht, rec\n",
    "def FFNN_Train(data, s1, s2, s3, activ, ro):\n",
    "    X,Y,W,B,S = FFNN_Initialize(data, s1, s2, s3)\n",
    "\n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        Z,A = FFNN_FeedForward(X[i],Y[i],W,B,S, activ)\n",
    "        W,B = FFNN_BackProp(Z,A,Y[i],W,B,S, activ, ro)\n",
    "    \n",
    "    print(\"training complete\")\n",
    "    return W,B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FFNN_Test(data, s1, s2, s3, activ, W,B):\n",
    "    X,Y,temp,temp2,S = FFNN_Initialize(data,s1,s2,s3)\n",
    "\n",
    "    error = 0\n",
    "    print(\"testing to begin\")\n",
    "    for i in range(len(X)):\n",
    "        Z,A = FFNN_FeedForward(X[i],Y[i],W,B,S,activ)\n",
    "        error += np.abs(Y[i] - A[2])\n",
    "        #print('Z: ', Z[2],' A :', A[2], ' Y: ', Y[i])\n",
    "      \n",
    "    \n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Auto Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# W's shape is as follows: W[l][s(l+1)][s(l)]\n",
    "\n",
    "def Auto_Initialize(data, s1, s2, s3):\n",
    "    X = [0] * s1\n",
    "    X = np.mat(X)\n",
    "    Y = []\n",
    "    temp = 0\n",
    "    tempx = []\n",
    "    cat = len(data[0])\n",
    "    for i in range(len(data[0])):\n",
    "        tempx = downsampleImage(data[0][i])\n",
    "        tempx = np.mat(tempx)   \n",
    "        X = np.vstack((X,tempx))\n",
    "\n",
    "    \n",
    "    X = X[1:][:]\n",
    "    Y = X\n",
    "    \n",
    "    B = []\n",
    "    S = [s1,s2,s3,1]\n",
    "    W = [0] * 3\n",
    "    for i in range(len(W)):\n",
    "        W[i] = [0] * S[i+1]\n",
    "        for j in range(len(W[i])):\n",
    "            W[i][j] = [np.random.rand() * 0.0001] * S[i]\n",
    "       \n",
    "    for i in range(len(S) -2):\n",
    "        B.append(np.random.rand() * 0.0001)\n",
    "    \n",
    "    return X,Y,W,B,S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activ takes the following values: sig, ht, rec\n",
    "def Auto_Encode(data, s1, s2, s3, activ, ro):\n",
    "    X,Y,W,B,S = Auto_Initialize(data, s1, s2, s3)\n",
    "\n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        Z,A = FFNN_FeedForward(X[i],Y[i],W,B,S, activ)\n",
    "        W,B = FFNN_BackProp(Z,A,Y[i],W,B,S, activ, ro)\n",
    "    \n",
    "    print(\"training complete\")\n",
    "    return W,B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#W,B = Auto_Encode(Y_train, 340, 3, 340, 'ht', 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Testing Algorithms on Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.a. Testing NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training complete\n",
      "testing to begin\n",
      "[ 35.00000424]\n"
     ]
    }
   ],
   "source": [
    "# 1.\n",
    "\n",
    "# I'm pretty sure there's a bug in my code that's causing my NN to underperform.  \n",
    "# However I'm up against the time deadline and I need to keep going.\n",
    "\n",
    "# used to determine my best parameters takes forever to run, I don't recommend it\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "ros = [1e-05,1e-06, 1e-07]\n",
    "s2s = [3,4,5,6,7]\n",
    "func = ['rec','sig','ht']\n",
    "bestRun = [0,0,0,1000000]\n",
    "\n",
    "for i in range(len(ros)):\n",
    "    for j in range(len(s2s)):\n",
    "        for k in range(len(func)):\n",
    "            print(\"ro: \", ros[i], \" s2: \", s2s[j], \" func: \", func[k])\n",
    "            W,B = FFNN_Train(Y_train, 340, s2s[j], 1, func[k], ros[i])\n",
    "            error = FFNN_Test(Y_test, 340, s2s[j], 1, func[k], W,B)\n",
    "            print(\"error: \", error)\n",
    "            if (error < bestRun[3]):\n",
    "                bestRun[0] = ros[i]\n",
    "                bestRun[1] = s2s[j]\n",
    "                bestRun[2] = func[k]\n",
    "                bestRun[3] = error\n",
    "\n",
    "print(\"Best Run:\", bestRun)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#Best Run: [1e-05, 3, 'sig', array([ 35.00000065])]\n",
    "W,B = FFNN_Train(Y_train, 340, 3, 1, 'sig', 1e-05)\n",
    "error = FFNN_Test(Y_test, 340, 3, 1, 'sig', W,B)\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.b. 1 v all SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Data_Flattener(data,s):\n",
    "    X = [0] * s\n",
    "    X = np.mat(X)\n",
    "    Y = []\n",
    "    temp = 0\n",
    "    tempx = []\n",
    "    cat = len(data[0])\n",
    "    for i in range(len(data[0])):\n",
    "        tempx = downsampleImage(data[0][i])\n",
    "        tempx = np.mat(tempx)   \n",
    "        #print(tempx.shape)\n",
    "        X = np.vstack((X,tempx))\n",
    "        temp = [i] * len(tempx)\n",
    "        Y.append(temp)\n",
    "    \n",
    "    X = X[1:][:]\n",
    "    Y = np.array(Y).flatten()\n",
    "    \n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def kernelGen(X):\n",
    "    K = []\n",
    "    for i in range(len(X)):\n",
    "        temp = []\n",
    "        for j in range(len(X)):\n",
    "            xi = np.mat(X[i])\n",
    "            xj = np.mat(X[j])\n",
    "            \n",
    "            temp.append(np.dot(xi,xj.T).A)\n",
    "        K.append(np.concatenate(temp).ravel().tolist())\n",
    "\n",
    "    return K\n",
    "def dualF(Y,K,j,b,alpha):\n",
    "    E = 0\n",
    "    for i in range(len(K)):\n",
    "        innx = K[i][j]\n",
    "        \n",
    "        E += (alpha[i] * Y[i] * innx)\n",
    "        \n",
    "    E = E + b - Y[j]\n",
    "    \n",
    "    \n",
    "    return E\n",
    "def simplifiedSMO(K,Y,c,tol,maxPass):\n",
    "    alpha = np.zeros((len(K)))\n",
    "    b = 0\n",
    "    passes = 0\n",
    "    while(passes < maxPass):\n",
    "        num_changed_alphas = 0\n",
    "        for i in range(len(K)):\n",
    "            Ei = dualF(Y, K, i, b, alpha)\n",
    "            temp = Ei * Y[i]\n",
    "            \n",
    "            if (((temp < (-1 * tol)) and (alpha[i] < c)) or ((temp > tol) and (alpha[i] > 0))):\n",
    "                j = random.randint(0, len(K) -1)\n",
    "                while (j == i):\n",
    "                    j = random.randint(0, len(K) -1)\n",
    "                    \n",
    "                Ej = dualF(Y, K, j, b, alpha)\n",
    "                # Save off old Alphas\n",
    "                alOldi = alpha[i]\n",
    "                alOldj = alpha[j]\n",
    "                \n",
    "                # Calculate L and H\n",
    "                L = max(0, alpha[j] - alpha[i])\n",
    "                H = min(c, c + alpha[j] - alpha[i])\n",
    "                #print(str(L) + \" \" + str(H))\n",
    "                \n",
    "                if (L == H):\n",
    "                    continue\n",
    "                #calculate n (eta)\n",
    "                \n",
    "                n = (2* K[i][j]) - (K[i][i]) - (K[j][j])\n",
    "                if (type(n) == 'float'):\n",
    "                    if (n >= 0):\n",
    "                        continue\n",
    "                \n",
    "                #calculate new aj\n",
    "                alNewj = alOldj - ((Y[j] * (Ei - Ej))/n)\n",
    "                alNewj = np.clip(alNewj, 0, c)\n",
    "                \n",
    "                \n",
    "                if (alNewj > H):\n",
    "                    alNewj = H\n",
    "                elif (alNewj < L):\n",
    "                    alNewj = L\n",
    "                \n",
    "                if (abs(alNewj - alOldj) < 10**(-5)):\n",
    "                    continue\n",
    "                \n",
    "                alNewi = alOldi + (Y[i] * Y[j] * (alOldj - alNewj))\n",
    "                alNewi = np.clip(alNewi, 0, c)\n",
    "                \n",
    "                alpha[i] = alNewi\n",
    "                alpha[j] = alNewj\n",
    "                \n",
    "                # calculate bs\n",
    "                b1 = b - Ei - (Y[i] * (alpha[i] - alOldi) * K[i][i]) - (Y[j] * (alpha[j] - alOldj) * K[i][j])\n",
    "                b2 = b - Ej - (Y[i] * (alpha[i] - alOldi) * K[i][j]) - (Y[j] * (alpha[j] - alOldj) * K[j][j])\n",
    "                \n",
    "                b = (b1 + b2)/2\n",
    "                \n",
    "                if ((0 < alpha[i]) and (alpha[i] < c)):\n",
    "                    b = b1\n",
    "                elif ((0 < alpha[j]) and (alpha[i] < c)):\n",
    "                    b = b2\n",
    "                \n",
    "                num_changed_alphas += 1\n",
    "                \n",
    "                #w = CostW(K,Y,alpha)\n",
    "                #print(w)\n",
    "            #end if\n",
    "        #end for\n",
    "        if (num_changed_alphas == 0):\n",
    "            passes += 1\n",
    "        else:\n",
    "            passes = 0\n",
    "            \n",
    "    return [alpha, b]\n",
    "def errorFSVM(Y, Ycomp):\n",
    "    error = 0\n",
    "    for i in range(len(Y)):\n",
    "        if(Y[i] != Ycomp[i]):\n",
    "            error += 1\n",
    "\n",
    "    error = error / len(Y)  \n",
    "    return error\n",
    "def YPrep(Y, i):\n",
    "    Y_temp = [0] * len(Y)\n",
    "    for j in range(len(Y)):\n",
    "        if (Y[j] != i):\n",
    "            Y_temp[j] = -1\n",
    "        else:\n",
    "            Y_temp[j] = 1\n",
    "    return Y_temp  \n",
    "\n",
    "def SVMForAll(data, cat):\n",
    "    #30336\n",
    "    c = 0.5\n",
    "    tol = 10**(-5)\n",
    "    max_pass = 50\n",
    "    X, Y = Data_Flattener(data, 340)\n",
    "    X = np.mat(X)\n",
    "    K = kernelGen(X)\n",
    "    \n",
    "    F = [0] * cat\n",
    "    for i in range(cat):\n",
    "        Y_temp = YPrep(Y,i)\n",
    "        F[i] = simplifiedSMO(K,Y_temp,c, tol, max_pass)\n",
    "        print(\"Class:\", i, \"vs all\")\n",
    "        SVMPost(F[i], X, Y_temp)\n",
    "        \n",
    "    return F    \n",
    "\n",
    "def SVMPost(F, X, Y_temp):\n",
    "    alpha = F[0]\n",
    "    b = F[1]\n",
    "\n",
    "    Wstar = 0\n",
    "    for i in range(len(X)):\n",
    "        Wstar += alpha[i]*Y_temp[i]*X[i]\n",
    "    \n",
    "    w = np.mat(Wstar)\n",
    "    X = np.mat(X).T\n",
    "\n",
    "    bias = np.mean(Y_temp - (w * X))\n",
    "\n",
    "    Y = np.sign((w * X) + bias)\n",
    "\n",
    "    #plt.plot(X.T, Y.T, 'o')\n",
    "    #plt.plot(X.T, Y_trn, '.')\n",
    "    error = errorFSVM(Y.T, Y_temp)\n",
    "\n",
    "    print(\"training error: \", error * 100, \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 0 vs all\n",
      "training error:  44.285714285714285 %\n",
      "Class: 1 vs all\n",
      "training error:  36.42857142857142 %\n",
      "Class: 2 vs all\n",
      "training error:  40.714285714285715 %\n",
      "Class: 3 vs all\n",
      "training error:  35.714285714285715 %\n",
      "Class: 4 vs all\n",
      "training error:  32.142857142857146 %\n",
      "Class: 5 vs all\n",
      "training error:  45.0 %\n",
      "Class: 6 vs all\n",
      "training error:  42.857142857142854 %\n",
      "Class: 7 vs all\n",
      "training error:  35.714285714285715 %\n",
      "Class: 8 vs all\n",
      "training error:  41.42857142857143 %\n",
      "Class: 9 vs all\n",
      "training error:  41.42857142857143 %\n"
     ]
    }
   ],
   "source": [
    "# This one takes a while to run.  Might want to make some Tea.\n",
    "F = SVMForAll(Y_test, 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.c. 1 v all LogRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def H(x, w):\n",
    "    h =  x * w\n",
    "    h = 1 + np.exp(h)\n",
    "    h = 1/h\n",
    "    h = h.flatten()\n",
    "    return h[0][0]\n",
    "\n",
    "def gradientDescent(X, Y, w, alpha, ittr, batch):\n",
    "   # print(X, Y, w, alpha)\n",
    "    m = len(Y)\n",
    "    \n",
    "    for i in range(ittr):\n",
    "        batchIdx = math.floor((sp.rand(1) * m))\n",
    "        miniX = X[batchIdx]\n",
    "        miniY = Y[batchIdx]\n",
    "    \n",
    "        miniX = np.mat(miniX)\n",
    "        miniY = np.mat(miniY)\n",
    "        \n",
    "        temp = (miniY.T - H(miniX,w))\n",
    "        temp = temp * miniX\n",
    "        temp = temp * alpha\n",
    "        \n",
    "        # - 2 lambda w?\n",
    "        \n",
    "        w = w - temp.T\n",
    "        #print(H(miniX,w))\n",
    "    \n",
    "    return w\n",
    "\n",
    "def logRegress(X_trn, Y_trn, ittr, dim, lrnRate, batch):\n",
    "\n",
    "    X = np.mat(X_trn)\n",
    "    Y = np.mat(Y_trn).T\n",
    "    w = [0] * dim\n",
    "    \n",
    "    w = np.mat(w).T\n",
    "    \n",
    "    w = gradientDescent(X, Y, w, lrnRate, ittr, batch)\n",
    "    \n",
    "\n",
    "    return w\n",
    "\n",
    "def errorFLog(Y, Ycomp):\n",
    "    error = 0\n",
    "    for i in range(len(Y)):\n",
    "        if (Y[i] != Ycomp[i]):\n",
    "            error += 1\n",
    "    \n",
    "    error = error / len(Y)\n",
    "    return error \n",
    "\n",
    "def YPreplog(Y, i):\n",
    "    Y_temp = [0] * len(Y)\n",
    "    for j in range(len(Y)):\n",
    "        if (Y[j] != i):\n",
    "            Y_temp[j] = 0\n",
    "        else:\n",
    "            Y_temp[j] = 1\n",
    "    Y_temp = np.mat(Y_temp)\n",
    "    #print(Y_temp)\n",
    "    return Y_temp   \n",
    "\n",
    "def logRegressForAll(data, cat):\n",
    "    \n",
    "    X,Y = Data_Flattener(data,340)\n",
    "    ittr = 1000\n",
    "    lrnRate = 0.01\n",
    "    batch = 1\n",
    "    \n",
    "    W = [0] * cat\n",
    "    for i in range(cat):\n",
    "        Y_temp = YPreplog(Y,i)\n",
    "        W[i] = logRegress(X, Y_temp,ittr, 340,lrnRate, batch)\n",
    "        print(\"Class:\", i, \"vs all\")\n",
    "        logRegressPost(W[i],X,Y_temp)\n",
    "          \n",
    "    return W\n",
    "\n",
    "def logRegressPost(w,X,Y_temp):\n",
    "    Y_sol = []\n",
    "    for i in range(len(X)):\n",
    "        Y_sol.append(np.round(H(X[i], w)).A1[0])\n",
    "    \n",
    "    #print(Y_sol)\n",
    "    Y_sol = np.mat(Y_sol)\n",
    "    #print(\"W: \", w)\n",
    "\n",
    "    error = errorFLog(Y_temp.T, Y_sol.T)\n",
    "    print(\"Training error: \", error * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 0 vs all\n",
      "Training error:  0.0 %\n",
      "Class: 1 vs all\n",
      "Training error:  0.0 %\n",
      "Class: 2 vs all\n",
      "Training error:  0.0 %\n",
      "Class: 3 vs all\n",
      "Training error:  0.8 %\n",
      "Class: 4 vs all\n",
      "Training error:  0.0 %\n",
      "Class: 5 vs all\n",
      "Training error:  1.4000000000000001 %\n",
      "Class: 6 vs all\n",
      "Training error:  0.0 %\n",
      "Class: 7 vs all\n",
      "Training error:  0.0 %\n",
      "Class: 8 vs all\n",
      "Training error:  0.0 %\n",
      "Class: 9 vs all\n",
      "Training error:  0.0 %\n"
     ]
    }
   ],
   "source": [
    "W = logRegressForAll(Y_train, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.d. PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernelGenPCA(X):\n",
    "    K = []\n",
    "    for i in range(len(X)):\n",
    "        temp = []\n",
    "        for j in range(len(X)):\n",
    "            xi = np.mat(X[i])\n",
    "            xj = np.mat(X[j])\n",
    "            \n",
    "            temp.append(np.dot(xi,xj.T).A)\n",
    "        K.append(np.concatenate(temp).ravel().tolist())\n",
    "\n",
    "    return K\n",
    "\n",
    "def KPCA(Y, d):\n",
    "    K = kernelGenPCA(Y)\n",
    "    #K = KTilda(K)\n",
    "    \n",
    "    K_eig = np.linalg.eig(K)\n",
    "    lam = K_eig[0]\n",
    "    W = K_eig[1]\n",
    "    #print('shape of the lambdas is [%d]' % lam.shape)\n",
    "    #print('shape of the W is [%d, %d]' % W.shape)\n",
    "    \n",
    "    for i in range(len(lam)):\n",
    "        W[i] *= 1/lam[i]\n",
    "    \n",
    "    W_tild = []\n",
    "    tempL = lam\n",
    "    tempW = np.array(W)\n",
    "    for i in range(d):\n",
    "        topLam = np.argmax(tempL)\n",
    "        W_tild.append(tempW[topLam])\n",
    "        \n",
    "        tempL = np.delete(tempL, topLam)\n",
    "        tempW = np.delete(tempW, topLam, 0)\n",
    "    \n",
    "    W_tild = np.mat(W_tild)\n",
    "    #print(W_tild)\n",
    "    X = W_tild * K\n",
    "    \n",
    "    return X.A\n",
    "\n",
    "def KPCAprep(data, d):\n",
    "    X,Y = Data_Flattener(data, 340)\n",
    "    X = KPCA(X, d)\n",
    "    \n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCAlogRegressForAll(X,Y, cat, d):\n",
    "\n",
    "    ittr = 1000\n",
    "    lrnRate = 0.01\n",
    "    batch = 1\n",
    "    \n",
    "    W = [0] * cat\n",
    "    for i in range(cat):\n",
    "        Y_temp = YPreplog(Y,i)\n",
    "        W[i] = logRegress(X, Y_temp,ittr, d,lrnRate, batch)\n",
    "        print(\"Class:\", i, \"vs all\")\n",
    "        logRegressPost(W[i],X,Y_temp)\n",
    "          \n",
    "    return W\n",
    "\n",
    "def PCASVMForAll(X,Y, cat):\n",
    "    #30336\n",
    "    c = 0.5\n",
    "    tol = 10**(-5)\n",
    "    max_pass = 50\n",
    "    X = np.mat(X)\n",
    "    K = kernelGen(X)\n",
    "    \n",
    "    F = [0] * cat\n",
    "    for i in range(cat):\n",
    "        Y_temp = YPrep(Y,i)\n",
    "        F[i] = simplifiedSMO(K,Y_temp,c, tol, max_pass)\n",
    "        print(\"Class:\", i, \"vs all\")\n",
    "        SVMPost(F[i], X, Y_temp)\n",
    "        \n",
    "    return F    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Regress for All:\n",
      "Class: 0 vs all\n",
      "Training error:  0.0 %\n",
      "Class: 1 vs all\n",
      "Training error:  0.0 %\n",
      "Class: 2 vs all\n",
      "Training error:  0.0 %\n",
      "Class: 3 vs all\n",
      "Training error:  0.0 %\n",
      "Class: 4 vs all\n",
      "Training error:  0.0 %\n",
      "Class: 5 vs all\n",
      "Training error:  0.0 %\n",
      "Class: 6 vs all\n",
      "Training error:  10.0 %\n",
      "Class: 7 vs all\n",
      "Training error:  10.0 %\n",
      "Class: 8 vs all\n",
      "Training error:  0.0 %\n",
      "Class: 9 vs all\n",
      "Training error:  0.0 %\n",
      "SVM for All:\n"
     ]
    }
   ],
   "source": [
    "X,Y = KPCAprep(Y_train, 100)\n",
    "print(\"Log Regress for All:\")\n",
    "W = PCAlogRegressForAll(X.T,Y,10, 100)\n",
    "print(\"SVM for All:\")\n",
    "# This takes so long to run I wouldn't recommend it.\n",
    "#F = PCASVMForAll(X,Y,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.e Auto Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.f PCA Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/core/numeric.py:531: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAD8CAYAAABkbJM/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJhiGYRiGL0wwDMMwDF/8X0dM2kDLA94FAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fca92a5c438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X,Y = KPCAprep(Y_train, 2)\n",
    "\n",
    "colors = ['g.','b.','y.','r.', 'c.', 'm.', 'k.', 'w.', 'burlywood.', 'chartreuse.']\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    for j in range(len(Y)):\n",
    "        if (Y[j] == i):\n",
    "            plt.plot(X[0][j],X[1][j], colors[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.g K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidDist(X,Y):\n",
    "    X = np.mat(X)\n",
    "    Y = np.mat(Y)\n",
    "    \n",
    "    cost = np.linalg.norm(X-Y,2)\n",
    "    cost = cost**2\n",
    "    \n",
    "    return cost;\n",
    "\n",
    "def assignCenters(X,C):\n",
    "    Z = np.zeros(len(X))\n",
    "    for i in range(len(X)):\n",
    "        bestc = -1;\n",
    "        bestCost = -1;\n",
    "        for j in range(len(C)):\n",
    "            tempCost = euclidDist(X[i],C[j])\n",
    "            if (bestCost == -1):\n",
    "                bestc = j\n",
    "                bestCost = tempCost\n",
    "            else:\n",
    "                if(tempCost < bestCost):\n",
    "                    bestc = j\n",
    "                    bestCost = tempCost\n",
    "            \n",
    "        Z[i] = bestc    \n",
    "           \n",
    "    return Z       \n",
    "\n",
    "def calcCenters(X,Z,C):\n",
    "    # Needs to be re-written for d > 2\n",
    "    X = np.mat(X)\n",
    "    \n",
    "    for i in range(len(C)):\n",
    "        tempC = [[0.0] * len(X.T)]\n",
    "        tempC = np.mat(tempC)\n",
    "        tempCount = 0\n",
    "        for j in range(len(Z)):\n",
    "            if (Z[j] == i):\n",
    "                np.add(tempC, X[j], out=tempC, casting='unsafe')\n",
    "                #tempC += X[j]\n",
    "                tempCount += 1\n",
    "        if (tempCount > 1):        \n",
    "            tempC = tempC/tempCount\n",
    "        #print(tempC)\n",
    "        C[i] = tempC.A.tolist()\n",
    "    return C\n",
    "\n",
    "def checkConverge(newC,oldC):\n",
    "    tol = 10**(-6)\n",
    "    for i in range(len(newC)):\n",
    "        temp = abs(euclidDist(newC[i], oldC[i]))\n",
    "        #print(temp)\n",
    "        if (temp > tol):\n",
    "            return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "def checkZConverge(newZ, oldZ):\n",
    "    for i in range(len(newZ)):\n",
    "        if (newZ[i] != oldZ[i]):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def Kmeans(X,k,seed):\n",
    "    np.random.seed(seed)\n",
    "    C = []\n",
    "    Z = [0] * len(X)\n",
    "    for i in range(k):\n",
    "        tempC = math.floor((sp.rand(1) * len(X))[0])\n",
    "        C.append(X[tempC])\n",
    "    \n",
    "    converged = False\n",
    "    ittr = 0\n",
    "    \n",
    "    while(converged == False):\n",
    "        newZ = assignCenters(X,C)\n",
    "        \n",
    "        newC = calcCenters(X,newZ,C)\n",
    "        \n",
    "        converged = (checkConverge(newC,C) and checkZConverge(newZ, Z))\n",
    "            \n",
    "        Z = newZ\n",
    "        C = newC      \n",
    "        ittr += 1\n",
    "        \n",
    "        if (ittr > 1000):\n",
    "            converged = True\n",
    "        \n",
    "    \n",
    "    Cluster = []\n",
    "    for l in range(k):\n",
    "        tempCluster = []\n",
    "        for i in range(len(X)):\n",
    "            if(Z[i] == l):\n",
    "                tempCluster.append(X[i])\n",
    "        Cluster.append(tempCluster)       \n",
    "    \n",
    "    return [C,Z,k,Cluster]\n",
    "\n",
    "def KmeanCost(X,Z,C):\n",
    "    cost = 0\n",
    "    for i in range(len(X)):\n",
    "        center = C[int(Z[i])]\n",
    "        point = X[i]\n",
    "        cost += euclidDist(point,center)\n",
    "        \n",
    "    cost = cost / len(X)\n",
    "    return cost\n",
    "\n",
    "def KmeanMain(X,k,r):\n",
    "    bestrun = 0\n",
    "    bestCost = 100\n",
    "    for i in range(r):\n",
    "        k_val = Kmeans(X,k,i+1)\n",
    "        C = k_val[0]\n",
    "        Z = k_val[1]\n",
    "        k = k_val[2]\n",
    "        clusters = k_val[3]\n",
    "        \n",
    "        cost = KmeanCost(X,Z,C)\n",
    "        if (cost < bestCost):\n",
    "            bestCost = cost\n",
    "            bestrun = i+1\n",
    "        \n",
    "    pp.pprint(\"Min Cost: \" +  str(bestCost))\n",
    "    k_val = Kmeans(X,k,bestrun)\n",
    "    \n",
    "        \n",
    "    return k_val[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-5ca31c13413d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mData_Flattener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m340\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclusters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKmeanMain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-36-26091ed7615a>\u001b[0m in \u001b[0;36mKmeanMain\u001b[0;34m(X, k, r)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0mbestCost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mk_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKmeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-26091ed7615a>\u001b[0m in \u001b[0;36mKmeans\u001b[0;34m(X, k, seed)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverged\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mnewZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massignCenters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mnewC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalcCenters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnewZ\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-26091ed7615a>\u001b[0m in \u001b[0;36massignCenters\u001b[0;34m(X, C)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mbestCost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mtempCost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meuclidDist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbestCost\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0mbestc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-26091ed7615a>\u001b[0m in \u001b[0;36meuclidDist\u001b[0;34m(X, Y)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[1;32m   2223\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Duplicate axes given.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2224\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mord\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2225\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0m_multi_svd_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2226\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mord\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2227\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_multi_svd_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36m_multi_svd_norm\u001b[0;34m(x, row_axis, col_axis, op)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mrow_axis\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrollaxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrollaxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_uv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36msvd\u001b[0;34m(a, full_matrices, compute_uv)\u001b[0m\n\u001b[1;32m   1400\u001b[0m         \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D->d'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'd->d'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1402\u001b[0;31m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_realType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1403\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X,Y = Data_Flattener(Y_train, 340)\n",
    "clusters = KmeanMain(X, 10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
